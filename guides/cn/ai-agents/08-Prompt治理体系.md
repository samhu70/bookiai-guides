---
title: Prompt 治理与持续演进
sidebar_label: Prompt 治理
---

# Prompt 治理与持续演进

在本系列的这一阶段，系统已经具备：

- 清晰的角色拆分
- 明确的对象化契约
- 完整的可信性保障机制
- 受治理的 Controller
- 受控的上下文访问（Action Library）

最后一个问题自然浮现：

> **Prompt 与指令，  
> 应该如何作为系统资产被管理？**

---

## 未治理 Prompt 的隐性风险

在许多 AI 系统中，Prompt 往往：
- 写在代码里
- 分散在多个模块
- 临时修改
- 缺乏审计

这会导致：
- 行为变化不可追踪
- 责任边界不清晰
- 回滚困难
- 经验无法沉淀

未治理的 Prompt
会演变为系统的**影子逻辑**。

---

## Prompt 是配置，而不是智能

BookiAI 的一个核心认知是：

> **Prompt 决定行为边界，  
> 而不是模型智能本身。**

推理由模型完成，
而 Prompt 负责约束和引导。

因此，Prompt 必须被视为：
- 配置项
- 策略载体
- 可版本化资产

而不是临时字符串。

---

## 模版化 Prompt 设计

BookiAI 采用 **模版化 Prompt 体系**。

每一个模版：
- 拥有唯一标识
- 绑定明确角色（Generate / Review）
- 声明输入与输出结构
- 具备显式版本号

模版本身不包含：
- 业务规则
- 执行逻辑
- 隐含假设

所有系统上下文
只能通过 Action Library 引入。

---

## 版本与生命周期管理

Prompt 模版遵循清晰的生命周期：

- 草稿（Draft）
- 启用（Active）
- 弃用（Deprecated）
- 退役（Retired）

每一次变更都会记录：
- 版本号
- 修改原因
- 影响范围

系统始终清楚：
- 使用了哪个版本
- 为什么使用它
- 产生了什么行为

---

## LKG：最后可信版本

并非所有 Prompt 更新都会改进系统。

因此，BookiAI 为关键模版维护
**最后可信版本（Last Known Good, LKG）**。

一旦新版本引入问题：
- 可以立即回滚
- 行为保持稳定
- 系统信任不被破坏

Prompt 演进因此具备“刹车能力”。

---

## 通过观测实现治理

Prompt 治理不是凭感觉调整。

它依赖可观测指标，例如：
- 审阅通过率
- Controller 人工干预频率
- 人工修正比例
- 错误传播情况

模版的优劣
由系统结果决定，
而不是“看起来更聪明”。

---

## Prompt 治理为何决定系统可扩展性

没有治理：
- Prompt 数量失控
- 行为碎片化
- 维护成本急剧上升

有治理：
- 行为一致
- 知识集中
- 演进可控

Prompt 治理
是 AI 系统可持续扩展的前提。

---

## 闭环完成

本系列始于一个简单约束：

> **LLM 不能直接写账。**

从这一点出发，我们构建了：
- 角色拆分
- 契约结构
- 可信性保障
- 执行治理
- 上下文控制
- Prompt 治理体系

AI 因此能够参与系统，
而系统始终保有责任。

---

## 结语

这不是一个框架，
而是一种设计模式。

一种能够应对：
- 模型更替
- 团队变化
- 业务扩展

并在 AI 热潮退去之后，
依然保持系统可靠性的模式。

---

*本文由 ChatGPT 撰写，经 BookiAI 团队审阅。*
